{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import NLLLoss\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from helpful_files.networks import PROTO, avgpool, covapool, pL, pCL, fsL, fsCL, fbpredict\n",
    "from helpful_files.testing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Important Values\n",
    "\n",
    "# General settings\n",
    "datapath = '/data/dww78/mini_inat_shrunk/'                      # The location of your train, test, repr, and query folders. Make sure it ends in '/'!\n",
    "model = '../orig-proto/orig-proto-Train-000.pth'               # What model do you wish to evaluate, and where is it saved?\n",
    "gpu = 2                             # What gpu do you wish to run on?\n",
    "workers = 1                         # Number of cpu worker processes to use for data loading\n",
    "verbosity = 10                      # How many categories in between status updates \n",
    "ensemble = 4                        # How many models to evaluate in parallel\n",
    "k = 5                               # Evaluate top-k accuracy. Typically 1 or 5. \n",
    "torch.cuda.set_device(gpu) \n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Model characteristics\n",
    "covariance_pooling = False           # Did your model use covariance pooling?\n",
    "localizing = False                   # Did your model use localization?\n",
    "fewshot_local = False                # If you used localization: few-shot, or parametric? Few-shot if True, param if False\n",
    "network_width = 64                  # Number of channels at every layer of the network\n",
    "\n",
    "# Batch construction\n",
    "bsize = 64                          # Batch size\n",
    "boxes_available = 10                # Percentage of images with bounding boxes available (few-shot localization models only)\n",
    "include_masks = (localizing         # Include or ignore the bounding box annotations?\n",
    "                 and fewshot_local)\n",
    "n_trials = (10                      # Number of trials (few-shot localization models only)\n",
    "            if include_masks else 1)\n",
    "\n",
    "\n",
    "# Calculate embedding size based on model setup\n",
    "d = (network_width if not \n",
    "     covariance_pooling else\n",
    "     network_width**2)\n",
    "if localizing and not covariance_pooling:\n",
    "    d = network_width*2\n",
    "assert n_trials == 1 or include_masks, (\"Repeated trials will yield repeated identical results under this configuration.\"+\n",
    "                                        \"Please set ntrials to 1 or use a few-shot localizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load Testing Data\n",
    "\n",
    "d_boxes = torch.load(datapath + 'box_coords.pth')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4905, 0.4961, 0.4330],std=[0.1737, 0.1713, 0.1779])\n",
    "    ])\n",
    "\n",
    "repr_dataset = datasets.ImageFolder(\n",
    "    datapath+'repr', \n",
    "    loader = lambda x: load_transform(x, d_boxes, transform, include_masks))\n",
    "query_dataset = datasets.ImageFolder(\n",
    "    datapath+'query',\n",
    "    loader = lambda x: load_transform(x, d_boxes, transform, include_masks))\n",
    "repr_loader = torch.utils.data.DataLoader(\n",
    "    repr_dataset, \n",
    "    batch_sampler = OrderedSampler(repr_dataset, bsize),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "query_loader = torch.utils.data.DataLoader(\n",
    "    query_dataset,\n",
    "    batch_sampler = OrderedSampler(query_dataset, bsize),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "way = len(repr_dataset.classes)\n",
    "\n",
    "# Determine number of images with bounding boxes per-class\n",
    "catsizes = torch.LongTensor(np.array([t[1] for t in repr_dataset.imgs])).bincount().float()\n",
    "ngiv = (catsizes*boxes_available//100)\n",
    "for i in range(ngiv.size(0)):\n",
    "    if ngiv[i] == 0:\n",
    "        ngiv[i] = 1\n",
    "ngiv = ngiv.long().tolist()\n",
    "\n",
    "print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Make Models\n",
    "    \n",
    "models = [PROTO(network_width).cuda() for i in range(ensemble)]\n",
    "expander = avgpool()\n",
    "if localizing:\n",
    "    if fewshot_local:\n",
    "        expander = fsCL if covariance_pooling else fsL\n",
    "    else:\n",
    "        expander = pCL() if covariance_pooling else pL()\n",
    "elif covariance_pooling:\n",
    "    expander = covapool\n",
    "expanders = [expander for _ in range(ensemble)]\n",
    "\n",
    "# Load saved parameters\n",
    "model_state = torch.load(model)\n",
    "for i in range(ensemble):\n",
    "    models[i].load_state_dict(model_state[i])\n",
    "    models[i].eval()\n",
    "    # Zero out the bias on the final layer, since it doesn't do anything\n",
    "    models[i].process[-1].layers[-1].bias.data.zero_()\n",
    "\n",
    "# Load additional parameters for parametric localizer models\n",
    "if localizing and not fewshot_local:\n",
    "    fbcentroids = torch.load(model[:model.rfind('.')]+'_localizers'+model[model.rfind('.'):])\n",
    "    for i in range(ensemble):\n",
    "        expanders[i].centroids.data = fbcentroids[i]\n",
    "        expanders[i].cuda()\n",
    "\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                    EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You don't want to append your tensor to total _accum \n",
    "# until after you've completed the category, so that should\n",
    "# happen in the upper if then block and you should be concatenating\n",
    "# to running in the lower for loop\n",
    "# total _accum list should have 227 entries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# b is actually a different number for every class \n",
    "# esize = 4; total accum should be 4 x 227 x b x d\n",
    "# 227 classes, for each categories size of embeddings is of size b x d\n",
    "# list of length 4 containing lists of length 227, each element of list will be a b x d tensor\n",
    "\n",
    "# total accum: [[[bxd],..,[b227xd]], [[*bxd],...,[*b227xd]], [[**bxd],...[**b227xd]], [[***bxd],...,[***b227xd]]]\n",
    "# [4,227,b,d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate(models, loader, expanders, bcentroids, way, d):\n",
    "    esize = len(models)\n",
    "    total_accum = [[],[],[],[]]\n",
    "    catindex = 0\n",
    "    lastcat = -1\n",
    "    count = 0\n",
    "    running = [torch.zeros(0, d)]*4\n",
    "    counts = [0]*way\n",
    "    progress = torch.zeros(1, way)\n",
    "    for i, ((inp,_), cat) in enumerate(loader):\n",
    "        catindex = cat[0]\n",
    "\n",
    "        # Moving to another category\n",
    "        if catindex != lastcat: \n",
    "            if i != 0:\n",
    "                for j in range(esize):\n",
    "                    total_accum[j].append(running[j]) # Write the values\n",
    "                counts[lastcat] = count\n",
    "            lastcat = catindex # Record the current category\n",
    "            count = 0\n",
    "            running = [torch.zeros(0, d)]*4\n",
    "            progress[0, lastcat] = 1\n",
    "            # Plot progress\n",
    "            display.clear_output(wait=True)\n",
    "            pl.figure(figsize=(20,1))\n",
    "            pl.imshow(progress.numpy(), cmap='Greys')\n",
    "            pl.title(\"Accumulating category prototypes:\")\n",
    "            pl.xticks([])\n",
    "            pl.yticks([])\n",
    "            pl.show()\n",
    "            sleep(.01)\n",
    "\n",
    "        # Continue accumulating\n",
    "        inp = inp.cuda()\n",
    "        with torch.no_grad():\n",
    "            for j in range(esize):\n",
    "                out = models[j](inp) # b 64 10 10\n",
    "                out = expanders[j](out, bcentroids[j], None) # b d\n",
    "                running[j] = torch.cat((running[j], out.cpu()), 0)\n",
    "        count += inp.size(0)\n",
    "                                       \n",
    "    # Record last category\n",
    "    for j in range(esize):\n",
    "        total_accum[j].append(running[j])\n",
    "        counts[catindex] = count\n",
    "#     print(len(total_accum))\n",
    "#     print(len(total_accum[0]))\n",
    "#     for i in total_accum[0]:\n",
    "#         print(len(i))\n",
    "    return total_accum, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "# TODO: write predict functions using SVM (sci-kit), L2-norm nearest-neighbors, arg to predict fxn\n",
    "# will be list of all tensors rather than centroids\n",
    "# Overview:\n",
    "# take data structure total_accum, get labels, and turn it into an numpy array to feed into an SVM\n",
    "\n",
    "# convert total_accum into x_train, 4 different SVMs\n",
    "# train an SVM on xtrain and make a prediction, return that one prediction\n",
    "# xtrain: [sum(b)x64] - d is 64\n",
    "# create the labels: (sum(b) x 1)\n",
    "# first b entries in total accum come from category 0, next b from category 1....\n",
    "\n",
    "def SVM_train(total_accum):\n",
    "    #     total_accum = [227,b,d]\n",
    "    #     X_train: [9187, d]\n",
    "    #     Y_train: [9187x1]\n",
    "    print(\"entering SVM train\")\n",
    "    X_train = np.concatenate(tuple([i for i in total_accum]))\n",
    "\n",
    "    Y_train = []\n",
    "    for i in range(len(total_accum)):\n",
    "        b = len(total_accum[i]) \n",
    "        Y_train += [i]*b\n",
    "\n",
    "    #Create a svm Classifier\n",
    "#     clf = svm.LinearSVC() # Linear Kernel\n",
    "    #Train the model using the training sets\n",
    "#     clf.fit(X_train, Y_train)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    clf = CalibratedClassifierCV(base_estimator=LinearSVC(dual=False, class_weight= 'balanced'))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def predict(train_model, x_test):\n",
    "#     x_test = [64, 4096]\n",
    "    print(\"in predict\")\n",
    "    print(len(x_test))\n",
    "    print(len(x_test[0]))\n",
    "    #Predict the response for test dataset\n",
    "#     print(\"entering predict\")\n",
    "    clf = train_model\n",
    "#     y_pred = clf.predict(x_test)\n",
    "#     y_proba = clf.predict_proba(x_test)\n",
    "\n",
    "    y_proba = clf.predict_proba(x_test)\n",
    "    best_k = np.argsort(y_proba, axis=1)[:,-k:]\n",
    "#     print(y_proba.shape)\n",
    "#    -------------- DAVIS's code\n",
    "#     distmat = torch.sum((centroids-query)**2,-1).neg().view(-1, centroids.size(-2))\n",
    "#     return F.log_softmax(distmat, dim=-1)\n",
    "    return best_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(k, total_accum, bcentroids, models, loader, expanders, way):\n",
    "    esize = len(models)\n",
    "    right = [0]*esize\n",
    "    allright = [0]*esize\n",
    "    perclassacc = np.array([[0.]*way for _ in range(esize)])\n",
    "    catindex = 0\n",
    "    lastcat = -1\n",
    "    count = 0\n",
    "    allcount = 0\n",
    "    progress = torch.zeros(1, way)\n",
    "    train_models = []\n",
    "     \n",
    "    for i in range(esize):\n",
    "        train_models.append(SVM_train(total_accum[i]))\n",
    "    \n",
    "    for i, ((inp,_), cat) in enumerate(loader):\n",
    "        catindex = cat[0]\n",
    "        if catindex != lastcat: # We're about to move to another category\n",
    "            # Write the values\n",
    "            if i!= 0:\n",
    "                allcount += count\n",
    "                for j in range(esize):\n",
    "                    allright[j] += right[j] \n",
    "                    perclassacc[j, lastcat] = right[j]/count\n",
    "            lastcat = catindex # Record the current category\n",
    "            count = 0 # Reset divisor\n",
    "            right = [0]*esize # Reset accumulator\n",
    "            progress[0, lastcat] = 1\n",
    "            # Plot progress\n",
    "            display.clear_output(wait=True)\n",
    "            pl.figure(figsize=(20,1))\n",
    "            pl.imshow(progress.numpy(), cmap='Greys')\n",
    "            pl.title(\"Accumulating accuracy scores:\")\n",
    "            pl.xticks([])\n",
    "            pl.yticks([])\n",
    "            pl.show()\n",
    "            sleep(.01)\n",
    "\n",
    "        # Predict\n",
    "        inp = inp.cuda()\n",
    "        targ = cat.cuda()\n",
    "        with torch.no_grad():\n",
    "            for j in range(esize):\n",
    "                out = models[j](inp)\n",
    "                out = expanders[j](out, bcentroids[j], None)\n",
    "                out = predict(train_models[j], out.cpu())\n",
    "                pred = torch.tensor(out).cuda()\n",
    "#                 [64,5]\n",
    "#                 _, pred = out.topk(k, 1, True, True)\n",
    "                pred = pred.t() \n",
    "#     {pred should be [k x 64]}\n",
    "#                 expand = pred.eq(targ.view(1, -1).expand_as(pred))\n",
    "#                 print(expand.shape)\n",
    "#                 expand2 = pred.eq(targ.view(1, -1).expand_as(pred))[:k].view(-1)\n",
    "#                 print(expand2.shape)\n",
    "#                 expand3 = pred.eq(targ.view(1, -1).expand_as(pred))[:k].view(-1).sum(0, keepdim=True)\n",
    "#                 print(expand2.shape)\n",
    "                right[j] += pred.eq(targ.view(1, -1).expand_as(pred))[:k].view(-1).sum(0, keepdim=True).float().item()\n",
    "#                 right[j] += pred.eq(targ.expand_as(pred))[:k].view(-1).sum(0, keepdim=True).float().item()\n",
    "        count += inp.size(0)\n",
    "\n",
    "    # Record last category\n",
    "    allcount += count\n",
    "    for j in range(esize):\n",
    "        allright[j] += right[j]\n",
    "        perclassacc[j, catindex] = right[j]/count\n",
    "\n",
    "    # Final reporting / recording\n",
    "    allacc = [r/allcount for r in allright]\n",
    "    \n",
    "    return allacc, np.mean(perclassacc, axis=0), np.mean(perclassacc, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in predict\n",
      "46\n",
      "64\n",
      "in predict\n",
      "46\n",
      "64\n",
      "in predict\n",
      "46\n",
      "64\n",
      "in predict\n",
      "46\n",
      "64\n",
      "Accuracies and 95% confidence intervals\n",
      "Mean accuracy: \t\t21.85 \t+/- 0.92\n",
      "Per-class accuracy: \t8 \t+/- 0.60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acclist = []\n",
    "pcacclist = []\n",
    "alldispacc = np.zeros(way)\n",
    "for r in range(n_trials):\n",
    "    # Accumulate foreground/background prototypes, if using\n",
    "    fbcentroids = (accumulateFB(models, repr_loader, way, network_width, ngiv, bsize)\n",
    "                   if include_masks else \n",
    "                   [None]*ensemble)\n",
    "    # Accumulate category prototypes\n",
    "\n",
    "    SVM_points, counts = accumulate(models, repr_loader, expanders, \n",
    "                                   fbcentroids, way, d)\n",
    "    \n",
    "    # Score the models\n",
    "    allacc, dispacc, perclassacc = score(k, SVM_points, fbcentroids, models, \n",
    "                                         query_loader, expanders, way)\n",
    "    # Record statistics\n",
    "    acclist = acclist+allacc\n",
    "    pcacclist = pcacclist+list(perclassacc)\n",
    "    alldispacc += dispacc\n",
    "\n",
    "# Aggregate collected statistics\n",
    "accs = sum(acclist)/n_trials/ensemble\n",
    "pcaccs = sum(pcacclist)/n_trials/ensemble\n",
    "alldispacc = alldispacc/n_trials\n",
    "confs = 1.96*np.sqrt(np.var(acclist)/n_trials/ensemble)\n",
    "pcconfs = 1.96*np.sqrt(np.var(pcacclist)/n_trials/ensemble)\n",
    "\n",
    "# Report\n",
    "print(\"Accuracies and 95% confidence intervals\")\n",
    "print(\"Mean accuracy: \\t\\t%.2f \\t+/- %.2f\" % (accs*100, confs*100))\n",
    "print(\"Per-class accuracy: \\t%.f \\t+/- %.2f\" % (pcaccs*100, pcconfs*100))\n",
    "logcounts = [np.log10(c) for c in counts]\n",
    "pl.figure()\n",
    "pl.axhline(0,color='k')\n",
    "pl.scatter(counts, dispacc*100, s=4)\n",
    "z = np.polyfit(logcounts, np.array(dispacc)*100, 1)\n",
    "p = np.poly1d(z)\n",
    "pl.plot([min(counts),max(counts)], [p(min(logcounts)),p(max(logcounts))], \"r--\")\n",
    "pl.ylim([0,100])\n",
    "pl.xlabel('# Reference Images')\n",
    "pl.ylabel('Percentage Points')\n",
    "pl.xscale('log')\n",
    "pl.title('Per-Class Top-%d Accuracy' % k)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.delete();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fewshot",
   "language": "python",
   "name": "fewshot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
