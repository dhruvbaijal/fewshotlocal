{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/at677/fewshotlocal'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import NLLLoss, Conv2d\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "from helpful_files.networks import Network\n",
    "from helpful_files.training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Important Values\n",
    "\n",
    "# General settings\n",
    "datapath = '/data/db638/'   # The location of your train, test, repr, and query folders. Make sure it ends in '/'!\n",
    "savepath = 'myModel-100-new.pth'        # Where should your trained model(s) be saved, and under what name?\n",
    "gpu = 2                             # What gpu do you wish to train on?\n",
    "workers = 4                         # Number of cpu worker processes to use for data loading\n",
    "epoch = 10                          # Number of passes over the dataset before the learning rate is cut\n",
    "ncuts = 5                           # Number of times to cut the learning rate before training completes\n",
    "verbosity = 50                      # How many batches in between status updates \n",
    "ensemble = 4                        # How many models to train in parallel\n",
    "torch.cuda.set_device(gpu)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Batch construction\n",
    "way = 10                            # Number of classes per batch during training\n",
    "trainshot = 5                       # Number of images per class used to form prototypes\n",
    "testshot = 10                       # Number of images per class used to make predictions\n",
    "\n",
    "# Model construction\n",
    "folding = True                      # Use batch folding?\n",
    "covariance_pooling = False           # Use covariance pooling?\n",
    "localizing = False                   # Use localization?\n",
    "fewshot_local = False                # If you are using localization: few-shot, or parametric? Few-shot if True, param if False\n",
    "network_width = 512                  # Number of channels at every layer of the network\n",
    "\n",
    "# Data loading\n",
    "augmentation_flipping = True        # Horizontal flip data augmentation\n",
    "include_masks = (localizing         # Include or ignore the bounding box annotations?\n",
    "                 and fewshot_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load Training Data\n",
    "\n",
    "d_boxes = torch.load('/data/db638/github/fewshotlocal/helpful_files/box_coords.pth')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4905, 0.4961, 0.4330],std=[0.1737, 0.1713, 0.1779])\n",
    "    ])\n",
    "\n",
    "if folding:\n",
    "    # Batch folding has no reference/query distinction\n",
    "    shots = [trainshot+testshot]\n",
    "else:\n",
    "    # Standard setup\n",
    "    shots = [trainshot, testshot]\n",
    "if localizing and fewshot_local and not folding:\n",
    "    # Unfolded prototype localizers need another set of reference images to inform foreground/background predictions\n",
    "    shots = [trainshot, trainshot, testshot-trainshot]\n",
    "    \n",
    "train_dataset = datasets.ImageFolder(\n",
    "    datapath+'train', \n",
    "    loader = lambda x: load_transform(x, d_boxes, transform, augmentation_flipping, include_masks))\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler = ProtoSampler(train_dataset, way, shots),\n",
    "    num_workers = workers,\n",
    "    pin_memory = True)\n",
    "print('Data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../train/3171/3ca6def8d30b20df7800db6e9aec577a.bmp\n"
     ]
    }
   ],
   "source": [
    "print(list(d_boxes.keys())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d_boxes = dict()\n",
    "for key, value in d_boxes.items():\n",
    "    new_key = \"/data/db638/\"+key[3:]\n",
    "    new_d_boxes[new_key] = value\n",
    "\n",
    "d_boxes = new_d_boxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.conv3 = conv3x3(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "      \n",
    "        self.conv4 = conv3x3(inplanes, planes)\n",
    "        self.bn4 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(stride)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.num_batches_tracked = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.num_batches_tracked += 1\n",
    "\n",
    "        residual = x\n",
    "        residual = self.conv4(residual)\n",
    "        residual = self.bn4(residual)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block):\n",
    "        self.inplanes = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.layer1 = BasicBlock(3,64, 2)\n",
    "        self.layer2 = BasicBlock(64,128, 2)\n",
    "        self.layer3 = BasicBlock(128,256, 2)\n",
    "        self.layer4 = BasicBlock(256,512, 1)\n",
    "#         UNCOMMENT ONLY FOR COVARIANCE POOLING\n",
    "#         self.layer5 = nn.Conv2d(512, 128, kernel_size=1, stride=1)\n",
    "       \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # TODO: is this fine?\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "#         UNCOMMENT ONLY FOR COVARIANCE POOLING\n",
    "#         x = self.layer5(x)\n",
    "        return x/math.sqrt(network_width)\n",
    "\n",
    "\n",
    "def resnet12():\n",
    "    \"\"\"Constructs a ResNet-12 model.\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9374592 parameters in each neural net.\n",
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Make Models\n",
    "    \n",
    "models = [Network(network_width, folding, covariance_pooling,\n",
    "                  localizing, fewshot_local, shots).cuda() for i in range(ensemble)]\n",
    "for model in models:\n",
    "    model.encode = resnet12().cuda()\n",
    "optimizer = [optim.Adam(m.parameters(), lr=.001) for m in models]\n",
    "scheduler = [optim.lr_scheduler.LambdaLR(o, lambda x: 1/(2**x)) for o in optimizer]\n",
    "criterion = NLLLoss().cuda()\n",
    "\n",
    "nweights = sum([i.numel() for i in list(models[0].parameters())])\n",
    "print(nweights,\"parameters in each neural net.\")\n",
    "print('Ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                             TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images covered this round:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/at677/anaconda3/envs/fewshot/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of approx. 192270\n",
      "7500 of approx. 192270\n",
      "15000 of approx. 192270\n",
      "22500 of approx. 192270\n"
     ]
    }
   ],
   "source": [
    "# Do the Thing!\n",
    "\n",
    "start = time.time()\n",
    "trainlosses, acctracker = [[] for _ in range(ensemble)],[[] for _ in range(ensemble)]\n",
    "epochs = ncuts*epoch\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Adjust learnrate\n",
    "    if e%epoch == 0:\n",
    "        [s.step() for s in scheduler]\n",
    "    \n",
    "    # Train for one epoch\n",
    "    trainloss, acc = train(train_loader, models, optimizer, criterion, way, shots, verbosity)\n",
    "    \n",
    "    # Update the graphics, report\n",
    "    display.clear_output(wait=True)\n",
    "    for j in range(ensemble):\n",
    "        trainlosses[j].append(trainloss[j])\n",
    "        acctracker[j].append(acc[j])\n",
    "    pl.figure(1, figsize=(15,15))\n",
    "    for i in range(ensemble):\n",
    "        pl.subplot(ensemble,2,2*i+1)\n",
    "        pl.plot(trainlosses[i])\n",
    "        pl.ylim((0,3))\n",
    "        pl.title(\"Training Loss\")\n",
    "        pl.subplot(ensemble,2,2*i+2)\n",
    "        pl.plot(acctracker[i])\n",
    "        pl.ylim((0,1))\n",
    "        pl.title(\"Training Acc\")\n",
    "    pl.show()\n",
    "    print(\"Training loss is: \"+str(trainloss)+\n",
    "            \"\\nTraining accuracy is: \"+str(acc)+\"\\n\")\n",
    "    print(\"Approximately %.2f hours to completion\"%(  (time.time()-start)/(e+1)*(epochs-e)/3600  ))\n",
    "    print()\n",
    "    \n",
    "print(\"Training complete: %.2f hours total\" % ((time.time()-start)/3600)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "\n",
    "torch.save([m.encode.cpu().state_dict() for m in models], savepath)\n",
    "\n",
    "# If using parametric localization, save the extra parameters\n",
    "if localizing and not fewshot_local:\n",
    "    torch.save([m.postprocess.centroids.cpu() for m in models], \n",
    "               savepath[:savepath.rfind('.')]+'_localizers'+savepath[savepath.rfind('.'):])\n",
    "print(\"Models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up GPU space\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "Jupyter.notebook.session.delete();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fewshot",
   "language": "python",
   "name": "fewshot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
